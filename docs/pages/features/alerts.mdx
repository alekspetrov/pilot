import { Callout } from 'nextra/components'

# Alerts & Notifications

Pilot's event-driven alert engine monitors task execution, autopilot health, budget consumption, and security events, delivering notifications to Slack, Telegram, email, webhooks, and PagerDuty.

## Overview

The alert engine provides:

- **Event-driven architecture** â€” Events flow asynchronously through an evaluation pipeline
- **Rule-based evaluation** â€” Configurable conditions with cooldown enforcement
- **Multi-channel dispatch** â€” Parallel delivery to Slack, Telegram, email, webhook, PagerDuty
- **Severity filtering** â€” Route alerts by severity level to appropriate channels

<Callout type="info">
Pilot ships with 17 built-in alert types covering task lifecycle, budget, autopilot health, and security events. All rules are configurable via YAML.
</Callout>

### Event Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Executor   â”‚â”€â”€â”€â”€â–¶â”‚ Engine       â”‚â”€â”€â”€â”€â–¶â”‚ Event Channel  â”‚
â”‚  (events)   â”‚     â”‚ Adapter      â”‚     â”‚ (buffered: 100)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Channels   â”‚â—€â”€â”€â”€â”€â”‚ Dispatcher   â”‚â—€â”€â”€â”€â”€â”‚ Rule Evaluator â”‚
â”‚  (parallel) â”‚     â”‚              â”‚     â”‚ + Cooldown     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Event generation** â€” The executor emits events for task start, progress, completion, and failure
2. **Adapter conversion** â€” `EngineAdapter` converts executor events to alert events (avoids import cycles)
3. **Async queue** â€” Events enter a buffered channel (capacity 100) for non-blocking processing
4. **Rule evaluation** â€” Engine matches events against enabled rules, checking conditions and cooldowns
5. **Parallel dispatch** â€” Matching alerts route to configured channels concurrently via goroutines

### Severity Levels

| Level | Use Case | Example |
|-------|----------|---------|
| `info` | Informational, no action required | PR stuck in CI for 15 minutes |
| `warning` | Attention needed, not urgent | Daily spend at 80% of limit |
| `critical` | Immediate action required | Circuit breaker tripped, budget depleted |

### Built-in Event Types

Pilot monitors 17 event types across four categories:

**Task Lifecycle**
- `task_started` â€” Task execution began
- `task_progress` â€” Progress update received
- `task_completed` â€” Task finished successfully
- `task_failed` â€” Task failed with error
- `task_stuck` â€” No progress for configured duration
- `consecutive_failures` â€” Multiple tasks failed in sequence

**Budget & Cost**
- `budget_exceeded` â€” Budget limit breached
- `budget_warning` â€” Approaching budget threshold
- `daily_spend_exceeded` â€” Daily spend over threshold
- `budget_depleted` â€” Monthly budget exhausted
- `usage_spike` â€” Unusual cost increase detected

**Autopilot Health**
- `failed_queue_high` â€” Too many issues in failed queue
- `circuit_breaker_trip` â€” Autopilot circuit breaker activated
- `api_error_rate_high` â€” API errors exceeding threshold
- `pr_stuck_waiting_ci` â€” PR waiting on CI too long
- `deadlock` â€” No state transitions for extended period
- `heartbeat_timeout` â€” Executor heartbeat missed

**Security**
- `unauthorized_access` â€” Unauthorized access attempt
- `sensitive_file_modified` â€” Protected file changed
- `unusual_pattern` â€” Suspicious activity detected
- `escalation` â€” Repeated failures requiring human intervention

## Alert Channels

Pilot supports five alert channel types. Each channel can filter alerts by severity level, enabling routing of critical alerts to PagerDuty while sending informational alerts to Slack.

### Slack

Sends Block Kit formatted messages with color-coded attachments based on severity.

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `channel` | string | Yes | Slack channel name (e.g., `#alerts`) |

**Formatting:**
- Header block with severity emoji and level
- Section block with alert title and message
- Context block with type, source, and project metadata
- Color-coded attachment: `danger` (critical), `warning` (warning), `#0066cc` (info)

```yaml
- name: slack-alerts
  type: slack
  enabled: true
  severities: [critical, warning, info]
  slack:
    channel: "#pilot-alerts"
```

### Telegram

Sends MarkdownV2 formatted messages with emoji indicators.

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `chat_id` | integer | Yes | Telegram chat or group ID |

**Formatting:**
- Severity emoji header (ğŸš¨ critical, âš ï¸ warning, â„¹ï¸ info)
- Bold title and message body
- Metadata with type, source, and project
- Timestamp footer

```yaml
- name: telegram-alerts
  type: telegram
  enabled: true
  severities: [critical, warning]
  telegram:
    chat_id: -1001234567890
```

### Email (SMTP)

Sends HTML formatted emails with CSS styling and responsive layout.

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `to` | string[] | Yes | Recipient email addresses |
| `smtp_host` | string | Yes | SMTP server hostname |
| `smtp_port` | integer | Yes | SMTP server port |
| `from` | string | Yes | Sender email address |
| `username` | string | Yes | SMTP authentication username |
| `password` | string | Yes | SMTP authentication password |
| `subject` | string | No | Custom subject template |

**Subject templates:**
- `{{severity}}` â€” Alert severity level
- `{{type}}` â€” Event type
- `{{title}}` â€” Alert title

**Formatting:**
- Responsive HTML with inline CSS
- Color-coded alert boxes by severity
- Metadata table with type, source, project
- Alert ID and timestamp footer

```yaml
- name: email-oncall
  type: email
  enabled: true
  severities: [critical]
  email:
    to:
      - oncall@company.com
      - platform-team@company.com
    smtp_host: smtp.gmail.com
    smtp_port: 587
    from: pilot@company.com
    username: pilot@company.com
    password: ${SMTP_PASSWORD}
    subject: "[{{severity}}] Pilot: {{title}}"
```

### Webhook

Sends HTTP POST/PUT requests with JSON payload and optional HMAC-SHA256 signing.

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `url` | string | Yes | Webhook endpoint URL |
| `method` | string | No | HTTP method (`POST` or `PUT`, default: `POST`) |
| `headers` | map | No | Custom HTTP headers |
| `secret` | string | No | HMAC-SHA256 signing secret |

**Payload:** JSON-serialized `Alert` object with all fields.

**Signature:** When `secret` is configured, the request includes an `X-Signature-256` header with format `sha256=<hex-encoded-hmac>`.

```yaml
- name: internal-webhook
  type: webhook
  enabled: true
  severities: [critical, warning, info]
  webhook:
    url: https://api.internal.company.com/alerts
    method: POST
    headers:
      Authorization: "Bearer ${WEBHOOK_TOKEN}"
      X-Source: pilot
    secret: ${WEBHOOK_SECRET}
```

### PagerDuty

Sends events to PagerDuty Events API v2 with automatic deduplication.

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `routing_key` | string | Yes | PagerDuty integration routing key |
| `service_id` | string | No | Optional service identifier |

**API endpoint:** `https://events.pagerduty.com/v2/enqueue`

**Deduplication key:** `pilot-{type}-{source}` â€” Prevents duplicate incidents for the same alert.

**Severity mapping:**
- Pilot `critical` â†’ PagerDuty `critical`
- Pilot `warning` â†’ PagerDuty `warning`
- Pilot `info` â†’ PagerDuty `info`

**Payload fields:**
- `summary` â€” Combined title and message
- `source` â€” Alert source
- `component` â€” Always `pilot`
- `group` â€” Project path
- `class` â€” Alert type
- `custom_details` â€” Alert metadata

```yaml
- name: pagerduty-critical
  type: pagerduty
  enabled: true
  severities: [critical]
  pagerduty:
    routing_key: ${PAGERDUTY_ROUTING_KEY}
    service_id: P1234567
```

### Complete Configuration Example

This example shows all five channel types configured with severity filtering:

```yaml
alerts:
  enabled: true
  channels:
    # All alerts to Slack
    - name: slack-all
      type: slack
      enabled: true
      severities: [critical, warning, info]
      slack:
        channel: "#pilot-alerts"

    # Critical + warning to Telegram
    - name: telegram-ops
      type: telegram
      enabled: true
      severities: [critical, warning]
      telegram:
        chat_id: -1001234567890

    # Critical only to email
    - name: email-oncall
      type: email
      enabled: true
      severities: [critical]
      email:
        to: [oncall@company.com]
        smtp_host: smtp.gmail.com
        smtp_port: 587
        from: pilot@company.com
        username: pilot@company.com
        password: ${SMTP_PASSWORD}
        subject: "ğŸš¨ [{{severity}}] {{title}}"

    # All alerts to internal system
    - name: webhook-internal
      type: webhook
      enabled: true
      severities: [critical, warning, info]
      webhook:
        url: https://api.internal.company.com/pilot/alerts
        headers:
          Authorization: "Bearer ${INTERNAL_API_TOKEN}"
        secret: ${WEBHOOK_HMAC_SECRET}

    # Critical only to PagerDuty
    - name: pagerduty-oncall
      type: pagerduty
      enabled: true
      severities: [critical]
      pagerduty:
        routing_key: ${PAGERDUTY_ROUTING_KEY}
```

<Callout type="tip">
Use severity filtering to route alerts appropriately: critical alerts to PagerDuty for immediate response, warning alerts to Slack/Telegram for awareness, and info alerts to webhooks for logging and analytics.
</Callout>
